{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " # üìåACTIVIDAD 3: CLASIFICADOR K-NN.\n",
    " ## PASO 1: CARGA DE DATOS Y CREACI√ìN DEL MODELO.\n",
    " Crea el notebook saa_02_p04_a3_<tus_iniciales>.ipynb donde realizar esta actividad. Continuamos\n",
    "usando el fichero wine.csv para implementar ahora un clasificador KNN multiclase y tras construirlo\n",
    "volvemos a intentar mejorarlo eliminando caracter√≠sticas que no aporten demasiado, pero usando otro\n",
    "enfoque, porque ahora no podemos aplicar restricciones de tipo L1.\n",
    "\n",
    "a) Copia el fichero saa_u02_p04_a2_<tus_iniciales>.ipynb en el fichero\n",
    "saa_u02_p04_a3_<tus_iniciales>.ipynb para cargar los datos de manera similar a como lo\n",
    "hiciste antes y completa el resto de apartados. Cuando particiones los datos y realices otras\n",
    "operaciones aleatorias vuelve a utilizar una semilla aleatoria que coincida con la longitud de tu\n",
    "nombre concatenada a la de tu primer apellido y concatenada a la de tu segundo apellido.\n",
    "\n",
    " b) Continuamos usando un objeto multiclass.OneVsRestClassifier() para que utilice el\n",
    "m√©todo uno contra el resto y ahora un modelo de clasificaci√≥n de tipo\n",
    "neighbors.NeighborsClassifier con el valor de k (par√°metro n_neighbors) que prefieras.\n",
    "Borra el c√≥digo que imprime los par√°metros de las l√≠neas de los modelos de regresi√≥n porque k\n",
    "vecinos cercanos no usa l√≠nea (borra el apartado c) anterior).\n",
    "\n",
    " c) Entrena el modelo y muestra los valores de la matriz de confusi√≥n y las m√©tricas de eficiencia o\n",
    "alternativamente un informe de clasificaci√≥n donde aparezcan tanto para los datos de train\n",
    "como para los datos de test.\n",
    "\n",
    " d)  Muestra la curva ROC y el valor AUC de cada clase y del modelo en global en los datos de\n",
    "test. Para hacerlo ten en cuenta que ahora este modelo no implementa la funci√≥n\n",
    "decision_function() as√≠ que tendremos que utilizar predict_proba().\n",
    "\n",
    " e) Responde a la vista de los resultados de los apartados d) y e) ¬øGeneraliza bien o tiene\n",
    "overfitting?\n",
    "\n",
    " f) Borra el c√≥digo del resto de apartados anteriores."
   ],
   "id": "ceca679a8fcd78a4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PASO 2: MEJORA DEL MODELO CON SBS.\n",
    " La selecci√≥n secuencial de caracter√≠sticas (SBS) es una familia de algoritmos de b√∫squeda de tipo\n",
    "greedy1 (sistem√°ticos o ansiosos) que se utilizan para reducir la dimensionalidad d de un espacio de\n",
    "datos a una dimensi√≥n k donde k < d. El objetivo es seleccionar las k caracter√≠sticas que sean m√°s\n",
    "relevantes para el problema de entre las que hay originalmente. Esta t√©cnica puede ser muy √∫til sobre\n",
    "todo para aquellos algoritmos que no soportan regularizaci√≥n.\n",
    "\n",
    "\n",
    " Uno de estos algoritmos es el Sequential Backward Selection (SBS), que introduce un poco de\n",
    "sobrecarga para seleccionar estas caracter√≠sticas a cambio de mejorar mucho el rendimiento de su\n",
    "entrenamiento y funcionamiento.\n",
    "\n",
    "\n",
    " La idea del algoritmo SBS es bastante simple: elimina caracter√≠sticas secuencialmente de los datos\n",
    "actuales hasta alcanzar el n√∫mero de caracter√≠sticas deseado. Para decidir la caracter√≠stica a eliminar\n",
    "en cada etapa debemos usar una funci√≥n criterio que llamamos J y que hay que minimizar.\n",
    "\n",
    "\n",
    "El criterio calculado por la funci√≥n J puede ser simplemente la diferencia de eficiencia del modelo\n",
    "antes y despu√©s de eliminar la caracter√≠stica. As√≠ que en cada paso eliminamos la caracter√≠stica que\n",
    "menos p√©rdida de rendimiento genere. El algoritmo ser√°:\n",
    " 1. Inicializar k = d donde d es la dimensionalidad de todo el espacio de caracter√≠sticas de X.\n",
    " 2. Encontrar la caracter√≠stica x‚àí que maximiza el criterio x‚àí = argmax J(Xk-x) donde x œµ Xk"
   ],
   "id": "75d17c919f66400"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    " 1Algoritmos de tipo Greedy: hacen b√∫squedas escogiendo opciones localmente √≥ptimas y en general consiguen\n",
    "encontrar soluciones no siempre √≥ptimas a los problemas en un tiempo razonable, en contraste con los algoritmos\n",
    "exhaustivos que encuentran algunas de las soluciones √≥ptimas de los problemas pero con un esfuerzo much√≠simo\n",
    "mayor.\n"
   ],
   "id": "672ffaaf8c42632c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " 3. Eliminar la caracter√≠stica x‚àí del conjunto de caracter√≠sticas: Xk-1 = Xk ‚Äì x-; k= k-1\n",
    " 4. Terminar si K es el n√∫mero de caracter√≠sticas deseadas o sino volver al paso 2\n",
    "\n",
    " g)\n",
    " Aunque est√° implementado en\n",
    "scikit-learn\n",
    " , como es sencillo de hacer lo vamos a progrmar\n",
    "nosotros. As√≠ que manos a la obra, crea el fichero\n",
    "c√≥digo:"
   ],
   "id": "443d3a4cba09f1cc"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T14:20:05.241255Z",
     "start_time": "2025-03-14T14:20:03.782309Z"
    }
   },
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SBS_samartlop():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score, test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self.test_size, random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, X_test, y_test, self.indices_)  # Desempe√±o con todas las caracter√≠sticas\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            self.scores_.append(scores[best])\n",
    "\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "        return self\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:20:05.252290Z",
     "start_time": "2025-03-14T14:20:05.247363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform(self, X):\n",
    "    return X[:, self.indices_]\n",
    "\n",
    "def _calc_score(self, x_train, y_train, x_test, y_test, indices):\n",
    "    self.estimator.fit(x_train[:, indices], y_train)\n",
    "    y_pred = self.estimator.predict(x_test[:, indices])\n",
    "    score = self.scoring(y_test, y_pred)\n",
    "    return score\n"
   ],
   "id": "90bc774826d2644",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para utilizarlo, un ejemplo:\n",
   "id": "f89bef1476593fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T14:20:06.355492Z",
     "start_time": "2025-03-14T14:20:05.451184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from SBS_samartlop import SBS\n",
    "knn = KneighborsClassifier(n_neighbors=5)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)"
   ],
   "id": "d93c9eb5667ce820",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SBS_samartlop'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mSBS_samartlop\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SBS\n\u001B[0;32m      3\u001B[0m knn \u001B[38;5;241m=\u001B[39m KneighborsClassifier(n_neighbors\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      4\u001B[0m sbs \u001B[38;5;241m=\u001B[39m SBS(knn, k_features\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'SBS_samartlop'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Aunque esta implementaci√≥n de SBS ya divide internamente el dataset en train y test dentro de su\n",
    "funci√≥n fit(), externamente le proporcionamos como datos de trabajo el dataset X_train. As√≠ es como\n",
    "si internamente la clase SBS crease una divisi√≥n train + val + test para prevenir usar los datos de test\n",
    "durante el entrenamiento o la b√∫squeda de par√°metros, ya que SBS calcula scores de las mejores"
   ],
   "id": "1d42c498b377b50a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " caracter√≠sticas y si usamos el dataset test original podemos crear overfitting a esos datos de test y\n",
    "generar una medida de desempe√±o enga√±osa cuando usemos sus datos para comprobar si el modelo\n",
    "generaliza bien.\n",
    "\n",
    "\n",
    " h)\n",
    " Como el objeto\n",
    "sbs\n",
    " ha ido coleccionando los\n",
    "scores\n",
    " de cada etapa, podemos graficar la\n",
    "evoluci√≥n a medida que va quitando caracter√≠sticas. Adapta el siguiente c√≥digo y lo a√±ades a\n",
    "tu fichero (ten en cuenta que est√°s usando el objeto multiclase) y cuando lo ejecutes, a la vista\n",
    "del gr√°fico, ¬øEn qu√© rango de caracter√≠sticas funciona bien el modelo [desde, hasta]?"
   ],
   "id": "c6b6dcb41878b0fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KneighborsClassifier, KNeighborsClassifier\n",
    "from sbs_samartlop import SBS\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "# Le pedimos que pruebe hasta dejas solo 1\n",
    "sbs.fit(X_train, y_train)\n",
    "# Dibujamos como cambia el desempe√±o al cambiar el n¬∫ de caracter√≠sticas\n",
    "k_carac = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_carac, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('N¬∫ de caracter√≠sticas')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Desempe√±o vs n¬∫ caracter√≠sticas\")\n",
    "plt.show()"
   ],
   "id": "290c2cac64d1b56"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "i)\n",
    " Si al clasificador\n",
    "KNN\n",
    " le afectan cosas, intenta minimizar estas cosas antes de realizar la\n",
    "divisi√≥n en\n",
    "train + test\n",
    " . Adem√°s, por prudencia (porque nos est√° dando una medida del\n",
    "desempe√±o agrupado en las 3 clases) vamos a quedarnos con la cantidad de caracter√≠sticas\n",
    "mayor que tenga un mejor desempe√±o, es decir, si entre [1, 4] tiene buen desempe√±o, nos\n",
    "quedamos con 4 en vez de con 1 por si a alguna clase le afecta demasiado no tener alguna de\n",
    "las que descartemos, pero esa p√©rdida se enmascara con buenos resultados en las otra clases.\n",
    "As√≠ que nos quedar√≠amos con 4. Pero es necesario saber qu√© caracter√≠sticas son esas. Si adaptas\n",
    "este c√≥digo en el que ver√≠amos qu√© puedes saberlo suponiendo que hay 13 y queremos\n",
    "quedarnos con 3"
   ],
   "id": "302c539e7c94331a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "k3 = list(sbs.subsets_[10])\n",
    "print(df_vinos.columns[1:][k3])"
   ],
   "id": "762dec4d3b0cf7ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "j)\n",
    " Ahora crea un nuevo clasificador pero descartando las categor√≠as que el m√©todo anterior te\n",
    "indique que son descartables. Puedes adaptar el ejemplo. Calcula matriz, e informe de\n",
    "clasificaci√≥n para\n",
    "train\n",
    " y test (mira si generaliza) y la curva\n",
    "dos modelos. ¬øHay diferencias significativas?"
   ],
   "id": "798957a9004c14a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "knn.fit(X_train[:, k3], y_train)\n",
   "id": "b10f456d5f536063"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PASO 3: MEJORA DEL MODELO CON ENSEMBLES.\n",
    " . Compara el desempe√±o de los\n",
    "Otra aproximaci√≥n para hacer el mismo trabajo de encontrar caracter√≠sticas que se puedan descartar es\n",
    "usar random forest, un m√©todo ensemble que ya hemos comentado en esta unidad y que veremos con\n",
    "m√°s detalle en la siguiente unidad. Al usar random forest suponemos que la importancia media de las\n",
    "caracter√≠sticas decrece cuando los c√°lculos se hacen a partir de todos los √°rboles del bosque.\n",
    " En scikit-learn la implementaci√≥n de random forest que hay ya recopila informaci√≥n sobre la\n",
    "importancia de cada caracter√≠stica cuando se construye el bosque y se almacena en la propiedad\n",
    "feature_importances_ de un RandomForestClassifier.\n"
   ],
   "id": "6fbc54d336a2a818"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "k)\n",
    "Adapta el siguiente c√≥digo que utiliza un\n",
    "random forest\n",
    "de 500 √°rboles para averiguar la\n",
    "importancia de cada caracter√≠stica y haz un listado de mayor a menor importancia. ¬øCoincide\n",
    "con alguno de los m√©todos anteriores que hemos usado?"
   ],
   "id": "6097409cb6616f1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "carac_labels = df_vinos.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=123)\n",
    "forest.fit(X_train, y_train)\n",
    "importancias = forest.feature_importances_\n",
    "indices = np.argsort(importancias)[::-1]"
   ],
   "id": "c41aa6885b6576dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PASO 4: BUSCAR EL MEJOR MODELO\n",
    " Entrena estos clasificadores a ver si consigues mejorar el accuracy y el overfitting. No uses GridSearch,\n",
    "prefiero que uses manuealmente los modelos. Si quieres, si puedes usar validaci√≥n cruzada.\n",
    "‚Ä¢ Regresi√≥n log√≠stica.\n",
    "\n",
    " ‚Ä¢ SoftMax.\n",
    "\n",
    " ‚Ä¢ Perceptr√≥n.\n",
    "\n",
    " ‚Ä¢ Bagging\n",
    "\n",
    " ‚Ä¢ Boosting\n",
    "\n",
    " ‚Ä¢ Voting de 3 modelos\n",
    "\n",
    "‚Ä¢ Stacking de 3 modelos (los que quieras)"
   ],
   "id": "fff9445f1b26bcdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " #### ENTREGAR:\n",
    " e)\n",
    " C√≥digo de entrenamiento de modelos y captura de ejecuci√≥n de test, matriz de confusi√≥n,\n",
    "informe, curva ROC y AUC de cada uno. Guarda el mejor modelo a un fichero."
   ],
   "id": "fb1d891e9e6fa0f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "968da1fd2a4dc2c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
